<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to iml: Interpretable Machine Learning in R • iml</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to iml: Interpretable Machine Learning in R">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">iml</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.11.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/intro.html">Introduction to iml: Interpretable Machine Learning in R</a>
    </li>
    <li>
      <a href="../articles/parallel.html">Parallel computation of interpretation methods</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/giuseppec/iml/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to iml: Interpretable Machine
Learning in R</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/giuseppec/iml/blob/main/vignettes/intro.Rmd" class="external-link"><code>vignettes/intro.Rmd</code></a></small>
      <div class="hidden name"><code>intro.Rmd</code></div>

    </div>

    
    
<p>Machine learning models usually perform really well for predictions,
but are not interpretable. The iml package provides tools for analysing
any black box machine learning model:</p>
<ul>
<li><p>Feature importance: Which were the most important
features?</p></li>
<li><p>Feature effects: How does a feature influence the prediction?
(Accumulated local effects, partial dependence plots and individual
conditional expectation curves)</p></li>
<li><p>Explanations for single predictions: How did the feature values
of a single data point affect its prediction? (LIME and Shapley
value)</p></li>
<li><p>Surrogate trees: Can we approximate the underlying black box
model with a short decision tree?</p></li>
<li><p>The iml package works for any classification and regression
machine learning model: random forests, linear models, neural networks,
xgboost, etc.</p></li>
</ul>
<p>This document shows you how to use the iml package to analyse machine
learning models.</p>
<p>If you want to learn more about the technical details of all the
methods, read chapters from: <a href="https://christophm.github.io/interpretable-ml-book/agnostic.html" class="external-link uri">https://christophm.github.io/interpretable-ml-book/agnostic.html</a></p>
<div class="section level2">
<h2 id="data-boston-housing">Data: Boston Housing<a class="anchor" aria-label="anchor" href="#data-boston-housing"></a>
</h2>
<p>We’ll use the <code><a href="https://rdrr.io/pkg/MASS/man/Boston.html" class="external-link">MASS::Boston</a></code> dataset to demonstrate the
abilities of the iml package. This dataset contains median house values
from Boston neighbourhoods.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"Boston"</span>, package <span class="op">=</span> <span class="st">"MASS"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat</span></span>
<span><span class="co">#&gt; 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98</span></span>
<span><span class="co">#&gt; 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14</span></span>
<span><span class="co">#&gt; 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03</span></span>
<span><span class="co">#&gt; 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94</span></span>
<span><span class="co">#&gt; 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33</span></span>
<span><span class="co">#&gt; 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21</span></span>
<span><span class="co">#&gt;   medv</span></span>
<span><span class="co">#&gt; 1 24.0</span></span>
<span><span class="co">#&gt; 2 21.6</span></span>
<span><span class="co">#&gt; 3 34.7</span></span>
<span><span class="co">#&gt; 4 33.4</span></span>
<span><span class="co">#&gt; 5 36.2</span></span>
<span><span class="co">#&gt; 6 28.7</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="fitting-the-machine-learning-model">Fitting the machine learning model<a class="anchor" aria-label="anchor" href="#fitting-the-machine-learning-model"></a>
</h2>
<p>First we train a randomForest to predict the Boston median housing
value:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://giuseppec.github.io/iml/" class="external-link">"iml"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/" class="external-link">"randomForest"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"Boston"</span>, package <span class="op">=</span> <span class="st">"MASS"</span><span class="op">)</span></span>
<span><span class="va">rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html" class="external-link">randomForest</a></span><span class="op">(</span><span class="va">medv</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Boston</span>, ntree <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="using-the-iml-predictor-container">Using the iml Predictor() container<a class="anchor" aria-label="anchor" href="#using-the-iml-predictor-container"></a>
</h2>
<p>We create a <code>Predictor</code> object, that holds the model and
the data. The iml package uses R6 classes: New objects can be created by
calling <code>Predictor$new()</code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">Boston</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span> <span class="op">!=</span> <span class="st">"medv"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">predictor</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Predictor.html">Predictor</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">rf</span>, data <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">Boston</span><span class="op">$</span><span class="va">medv</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="feature-importance">Feature importance<a class="anchor" aria-label="anchor" href="#feature-importance"></a>
</h2>
<p>We can measure how important each feature was for the predictions
with <code>FeatureImp</code>. The feature importance measure works by
shuffling each feature and measuring how much the performance drops. For
this regression task we choose to measure the loss in performance with
the mean absolute error (‘mae’), another choice would be the mean
squared error (‘mse’).</p>
<p>Once we create a new object of <code>FeatureImp</code>, the
importance is automatically computed. We can call the
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> function of the object or look at the results in a
data.frame.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">imp</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/FeatureImp.html">FeatureImp</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, loss <span class="op">=</span> <span class="st">"mae"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org" class="external-link">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">imp</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">imp</span><span class="op">$</span><span class="va">results</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;    feature importance.05 importance importance.95 permutation.error</span></span>
<span><span class="co">#&gt; 1    lstat      3.996140   4.135837      4.317803          4.788590</span></span>
<span><span class="co">#&gt; 2       rm      2.685506   2.715282      2.889989          3.143832</span></span>
<span><span class="co">#&gt; 3  ptratio      1.666459   1.728166      1.745227          2.000920</span></span>
<span><span class="co">#&gt; 4      dis      1.612628   1.667092      1.699770          1.930207</span></span>
<span><span class="co">#&gt; 5      nox      1.504569   1.576274      1.581755          1.825055</span></span>
<span><span class="co">#&gt; 6     crim      1.509768   1.545514      1.611800          1.789441</span></span>
<span><span class="co">#&gt; 7    indus      1.297713   1.337473      1.356928          1.548565</span></span>
<span><span class="co">#&gt; 8      age      1.279583   1.302343      1.346693          1.507890</span></span>
<span><span class="co">#&gt; 9      tax      1.220118   1.226805      1.256486          1.420430</span></span>
<span><span class="co">#&gt; 10   black      1.177398   1.209823      1.232926          1.400768</span></span>
<span><span class="co">#&gt; 11     rad      1.054973   1.065001      1.070641          1.233089</span></span>
<span><span class="co">#&gt; 12      zn      1.022191   1.034042      1.039069          1.197244</span></span>
<span><span class="co">#&gt; 13    chas      1.010353   1.014358      1.018517          1.174453</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="feature-effects">Feature effects<a class="anchor" aria-label="anchor" href="#feature-effects"></a>
</h2>
<p>Besides knowing which features were important, we are interested in
how the features influence the predicted outcome. The
<code>FeatureEffect</code> class implements accumulated local effect
plots, partial dependence plots and individual conditional expectation
curves. The following plot shows the accumulated local effects (ALE) for
the feature ‘lstat’. ALE shows how the prediction changes locally, when
the feature is varied. The marks on the x-axis indicates the
distribution of the ‘lstat’ feature, showing how relevant a region is
for interpretation (little or no points mean that we should not
over-interpret this region).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ale</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/FeatureEffect.html">FeatureEffect</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, feature <span class="op">=</span> <span class="st">"lstat"</span>, grid.size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">ale</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;"></p>
<p>If we want to compute the partial dependence curves on another
feature, we can simply reset the feature:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ale</span><span class="op">$</span><span class="fu">set.feature</span><span class="op">(</span><span class="st">"rm"</span><span class="op">)</span></span>
<span><span class="va">ale</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="measure-interactions">Measure interactions<a class="anchor" aria-label="anchor" href="#measure-interactions"></a>
</h2>
<p>We can also measure how strongly features interact with each other.
The interaction measure regards how much of the variance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math>
is explained by the interaction. The measure is between 0 (no
interaction) and 1 (= 100% of variance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math>
due to interactions). For each feature, we measure how much they
interact with any other feature:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">interact</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Interaction.html">Interaction</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, grid.size <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'withr'</span></span></code></pre>
<pre><code><span><span class="co">#&gt; The following object is masked from 'package:tools':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     makevars_user</span></span></code></pre>
<pre><code><span><span class="co">#&gt; The following objects are masked from 'package:rlang':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     local_options, with_options</span></span></code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">interact</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;"></p>
<p>We can also specify a feature and measure all it’s 2-way interactions
with all other features:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">interact</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Interaction.html">Interaction</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, feature <span class="op">=</span> <span class="st">"crim"</span>, grid.size <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">interact</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;"></p>
<p>You can also plot the feature effects for all features at once:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">effs</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/FeatureEffects.html">FeatureEffects</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, grid.size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">effs</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="surrogate-model">Surrogate model<a class="anchor" aria-label="anchor" href="#surrogate-model"></a>
</h2>
<p>Another way to make the models more interpretable is to replace the
black box with a simpler model - a decision tree. We take the
predictions of the black box model (in our case the random forest) and
train a decision tree on the original features and the predicted
outcome. The plot shows the terminal nodes of the fitted tree. The
maxdepth parameter controls how deep the tree can grow and therefore how
interpretable it is.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tree</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/TreeSurrogate.html">TreeSurrogate</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, maxdepth <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Loading required package: partykit</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Loading required package: libcoin</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Loading required package: mvtnorm</span></span></code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">tree</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;"></p>
<p>We can use the tree to make predictions:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">tree</span><span class="op">$</span><span class="fu">predict</span><span class="op">(</span><span class="va">Boston</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Warning in self$predictor$data$match_cols(data.frame(newdata)): Dropping</span></span>
<span><span class="co">#&gt; additional columns: medv</span></span></code></pre>
<pre><code><span><span class="co">#&gt;     .y.hat</span></span>
<span><span class="co">#&gt; 1 28.78541</span></span>
<span><span class="co">#&gt; 2 21.91311</span></span>
<span><span class="co">#&gt; 3 28.78541</span></span>
<span><span class="co">#&gt; 4 28.78541</span></span>
<span><span class="co">#&gt; 5 28.78541</span></span>
<span><span class="co">#&gt; 6 28.78541</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="explain-single-predictions-with-a-local-model">Explain single predictions with a local model<a class="anchor" aria-label="anchor" href="#explain-single-predictions-with-a-local-model"></a>
</h2>
<p>Global surrogate model can improve the understanding of the global
model behaviour. We can also fit a model locally to understand an
individual prediction better. The local model fitted by
<code>LocalModel</code> is a linear regression model and the data points
are weighted by how close they are to the data point for wich we want to
explain the prediction.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lime.explain</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/LocalModel.html">LocalModel</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, x.interest <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; Loading required package: glmnet</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Loading required package: Matrix</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Loaded glmnet 4.1-8</span></span></code></pre>
<pre><code><span><span class="co">#&gt; Loading required package: gower</span></span></code></pre>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lime.explain</span><span class="op">$</span><span class="va">results</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;               beta x.recoded    effect x.original feature feature.value</span></span>
<span><span class="co">#&gt; rm       4.5149417     6.575 29.685741      6.575      rm      rm=6.575</span></span>
<span><span class="co">#&gt; ptratio -0.5696891    15.300 -8.716243       15.3 ptratio  ptratio=15.3</span></span>
<span><span class="co">#&gt; lstat   -0.4592951     4.980 -2.287290       4.98   lstat    lstat=4.98</span></span></code></pre>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">lime.explain</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lime.explain</span><span class="op">$</span><span class="fu">explain</span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">lime.explain</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;"></p>
</div>
<div class="section level2">
<h2 id="explain-single-predictions-with-game-theory">Explain single predictions with game theory<a class="anchor" aria-label="anchor" href="#explain-single-predictions-with-game-theory"></a>
</h2>
<p>An alternative for explaining individual predictions is a method from
coalitional game theory named Shapley value. Assume that for one data
point, the feature values play a game together, in which they get the
prediction as a payout. The Shapley value tells us how to fairly
distribute the payout among the feature values.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">shapley</span> <span class="op">&lt;-</span> <span class="va"><a href="../reference/Shapley.html">Shapley</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="va">predictor</span>, x.interest <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, sample.size <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">shapley</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;"></p>
<p>We can reuse the object to explain other data points:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">shapley</span><span class="op">$</span><span class="fu">explain</span><span class="op">(</span>x.interest <span class="op">=</span> <span class="va">X</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="va">shapley</span><span class="op">$</span><span class="fu">plot</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="intro_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;"></p>
<p>The results in data.frame form can be extracted like this:</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="va">shapley</span><span class="op">$</span><span class="va">results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">results</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;   feature         phi     phi.var feature.value</span></span>
<span><span class="co">#&gt; 1    crim  0.02236619  1.91975348  crim=0.02731</span></span>
<span><span class="co">#&gt; 2      zn -0.01757000  0.17093081          zn=0</span></span>
<span><span class="co">#&gt; 3   indus -0.54826667  2.34293197    indus=7.07</span></span>
<span><span class="co">#&gt; 4    chas -0.02603333  0.01361733        chas=0</span></span>
<span><span class="co">#&gt; 5     nox  0.44874333  1.35829579     nox=0.469</span></span>
<span><span class="co">#&gt; 6      rm -1.54282444 11.60060925      rm=6.421</span></span></code></pre>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Giuseppe Casalicchio, Christoph Molnar, <a href="https://pat-s.me" class="external-link">Patrick Schratz</a>.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

      </footer>
</div>






  </body>
</html>
